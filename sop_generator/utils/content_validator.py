from typing import Dict, List, Any, Optional, Tuple
from dataclasses import dataclass
from enum import Enum
import re
import json
from pathlib import Path

from .quality_assessment import ProfessionalSOPAssessor, SOPReadinessAssessment
from .equipment_engine import ProfessionalEquipmentEngine, EquipmentType
from .safety_integration import ProfessionalSafetyIntegrator


class ValidationLevel(Enum):
    BASIC = "basic"
    PROFESSIONAL = "professional"
    PRODUCTION_READY = "production_ready"


class ContentIssueType(Enum):
    TECHNICAL_ACCURACY = "technical_accuracy"
    COMPLETENESS = "completeness"
    INDUSTRY_STANDARDS = "industry_standards"
    SAFETY_COMPLIANCE = "safety_compliance"
    REGULATORY_COMPLIANCE = "regulatory_compliance"


@dataclass
class ValidationIssue:
    issue_type: ContentIssueType
    severity: str  # "critical", "major", "minor"
    section: str
    line_number: Optional[int]
    description: str
    current_content: str
    suggested_improvement: str
    reference_source: Optional[str] = None
    regulatory_requirement: Optional[str] = None


@dataclass
class ContentValidationResult:
    overall_score: float
    validation_level: ValidationLevel
    issues: List[ValidationIssue]
    enhancement_suggestions: List[Dict[str, Any]]
    missing_sections: List[str]
    technical_accuracy_score: float
    completeness_score: float
    safety_score: float
    regulatory_score: float


class RealTimeContentValidator:
    """Real-time SOP content validation and enhancement system"""
    
    def __init__(self):
        self.quality_assessor = ProfessionalSOPAssessor()
        self.equipment_engine = ProfessionalEquipmentEngine()
        self.safety_integrator = ProfessionalSafetyIntegrator()
        
        # Load validation patterns and references
        self.technical_patterns = self._load_technical_validation_patterns()
        self.industry_standards = self._load_industry_standards()
        self.reference_materials = self._load_reference_materials()
    
    def _load_technical_validation_patterns(self) -> Dict[str, Dict[str, Any]]:
        """Load technical validation patterns for accuracy checking"""
        return {
            "parameter_validation": {
                "temperature": {
                    "patterns": [r'(\d+(?:\.\d+)?)\s*[¬∞‚ÑÉ]\s*[CF]?'],
                    "typical_ranges": {
                        "ambient": (15, 30),
                        "elevated": (40, 200),
                        "high": (200, 1000)
                    },
                    "validation_rules": [
                        "Must include units",
                        "Must specify tolerance if critical",
                        "Must be within equipment capabilities"
                    ]
                },
                "pressure": {
                    "patterns": [r'(\d+(?:\.\d+)?)\s*(?:–±–∞—Ä|bar|–∫–ü–∞|–ú–ü–∞|–∞—Ç–º|psi)'],
                    "typical_ranges": {
                        "atmospheric": (0.8, 1.2),
                        "low_pressure": (1, 10),
                        "high_pressure": (10, 600)
                    },
                    "validation_rules": [
                        "Must include units",
                        "Must specify safety limits",
                        "Must include pressure relief information for high pressure"
                    ]
                },
                "flow_rate": {
                    "patterns": [r'(\d+(?:\.\d+)?)\s*(?:–º–ª/–º–∏–Ω|ml/min|–ª/–º–∏–Ω|L/min)'],
                    "typical_ranges": {
                        "analytical": (0.1, 5.0),
                        "preparative": (5, 50),
                        "process": (50, 1000)
                    },
                    "validation_rules": [
                        "Must include units",
                        "Must be compatible with column specifications",
                        "Must consider back-pressure limits"
                    ]
                }
            },
            "procedure_validation": {
                "step_numbering": {
                    "pattern": r'^\d+\.\s+',
                    "requirements": ["Sequential numbering", "Clear action verbs", "Measurable outcomes"]
                },
                "decision_points": {
                    "pattern": r'–µ—Å–ª–∏\s+.*,\s*—Ç–æ|–≤\s+—Å–ª—É—á–∞–µ\s+–µ—Å–ª–∏|–ø—Ä–∏\s+(?:–ø—Ä–µ–≤—ã—à–µ–Ω–∏–∏|–æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–∏)',
                    "requirements": ["Clear conditions", "Specific actions", "Escalation procedures"]
                },
                "success_criteria": {
                    "pattern": r'–∫—Ä–∏—Ç–µ—Ä–∏–π\s+(?:—É—Å–ø–µ—Ö–∞|–≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è|–ø—Ä–∏–µ–º–∫–∏)',
                    "requirements": ["Quantifiable metrics", "Acceptance ranges", "Verification methods"]
                }
            },
            "safety_validation": {
                "hazard_identification": {
                    "required_elements": ["Risk assessment", "Control measures", "PPE requirements", "Emergency procedures"],
                    "patterns": [r'–æ–ø–∞—Å–Ω–æ—Å—Ç—å|—Ä–∏—Å–∫|hazard', r'–°–ò–ó|PPE|–∑–∞—â–∏—Ç', r'–∞–≤–∞—Ä–∏–π|emergency']
                },
                "regulatory_compliance": {
                    "required_standards": ["–ì–û–°–¢", "–°–∞–Ω–ü–∏–ù", "ISO", "OSHA"],
                    "patterns": [r'–ì–û–°–¢\s+[\d.-]+', r'ISO\s+\d+', r'–°–∞–Ω–ü–∏–ù\s+[\d.]+']
                }
            }
        }
    
    def _load_industry_standards(self) -> Dict[str, Dict[str, Any]]:
        """Load industry standards database for validation"""
        return {
            "ISO_17025": {
                "title": "General requirements for the competence of testing and calibration laboratories",
                "sections": {
                    "7.2": "Selection, verification and validation of methods",
                    "7.3": "Sampling",
                    "7.4": "Handling of test or calibration items",
                    "7.7": "Ensuring the validity of results"
                },
                "required_elements": [
                    "Method validation parameters",
                    "Uncertainty estimation",
                    "Quality control procedures",
                    "Traceability requirements"
                ]
            },
            "ICH_Q2": {
                "title": "Validation of Analytical Procedures",
                "sections": {
                    "1": "Introduction", 
                    "2": "Types of Analytical Procedures",
                    "3": "Validation Characteristics",
                    "4": "Analytical Procedure Validation"
                },
                "required_elements": [
                    "Accuracy assessment",
                    "Precision evaluation",
                    "Linearity and range",
                    "Detection and quantitation limits",
                    "Robustness testing"
                ]
            },
            "GMP": {
                "title": "Good Manufacturing Practice",
                "sections": {
                    "2": "Quality Management",
                    "3": "Personnel",
                    "4": "Premises and Equipment",
                    "6": "Quality Control"
                },
                "required_elements": [
                    "Documentation control",
                    "Change control procedures",
                    "Deviation handling",
                    "CAPA system integration"
                ]
            }
        }
    
    def _load_reference_materials(self) -> Dict[str, List[str]]:
        """Load reference materials for content enhancement"""
        return {
            "equipment_manuals": [
                "Manufacturer operation manuals",
                "Maintenance and service guides",
                "Troubleshooting references",
                "Software user guides"
            ],
            "regulatory_guidance": [
                "FDA guidance documents",
                "EMA guidelines",
                "ICH harmonized tripartite guidelines",
                "National pharmacopeias"
            ],
            "industry_publications": [
                "Peer-reviewed journal articles",
                "Industry best practice guides",
                "Professional society standards",
                "Technical application notes"
            ]
        }
    
    def validate_content_real_time(self, 
                                 sop_content: str,
                                 equipment_type: str = None,
                                 reference_documents: List[str] = None,
                                 validation_level: ValidationLevel = ValidationLevel.PROFESSIONAL) -> ContentValidationResult:
        """Perform real-time content validation with enhancement suggestions"""
        
        issues = []
        enhancement_suggestions = []
        
        # Technical accuracy validation
        technical_issues, technical_score = self._validate_technical_accuracy(sop_content, equipment_type, reference_documents)
        issues.extend(technical_issues)
        
        # Completeness validation
        completeness_issues, completeness_score, missing_sections = self._validate_completeness(sop_content)
        issues.extend(completeness_issues)
        
        # Industry standards compliance
        standards_issues, standards_score = self._validate_industry_standards(sop_content, validation_level)
        issues.extend(standards_issues)
        
        # Safety compliance validation
        safety_issues, safety_score = self._validate_safety_compliance(sop_content, equipment_type)
        issues.extend(safety_issues)
        
        # Generate enhancement suggestions
        enhancements = self._generate_enhancement_suggestions(sop_content, issues, reference_documents)
        enhancement_suggestions.extend(enhancements)
        
        # Calculate overall score
        overall_score = (technical_score * 0.3 + completeness_score * 0.25 + 
                        standards_score * 0.20 + safety_score * 0.25)
        
        # Determine validation level achieved
        achieved_level = self._determine_validation_level(overall_score, issues)
        
        return ContentValidationResult(
            overall_score=overall_score,
            validation_level=achieved_level,
            issues=issues,
            enhancement_suggestions=enhancement_suggestions,
            missing_sections=missing_sections,
            technical_accuracy_score=technical_score,
            completeness_score=completeness_score,
            safety_score=safety_score,
            regulatory_score=standards_score
        )
    
    def _validate_technical_accuracy(self, 
                                   content: str, 
                                   equipment_type: str = None,
                                   reference_docs: List[str] = None) -> Tuple[List[ValidationIssue], float]:
        """Validate technical accuracy against reference materials"""
        
        issues = []
        score = 100.0
        
        # Parameter validation
        param_patterns = self.technical_patterns["parameter_validation"]
        
        for param_type, config in param_patterns.items():
            for pattern in config["patterns"]:
                matches = re.finditer(pattern, content, re.IGNORECASE)
                
                for match in matches:
                    value_str = match.group(1)
                    try:
                        value = float(value_str)
                        
                        # Check if value is within reasonable ranges
                        ranges = config["typical_ranges"]
                        in_range = False
                        
                        for range_type, (min_val, max_val) in ranges.items():
                            if min_val <= value <= max_val:
                                in_range = True
                                break
                        
                        if not in_range:
                            issues.append(ValidationIssue(
                                issue_type=ContentIssueType.TECHNICAL_ACCURACY,
                                severity="major",
                                section=f"–ü–∞—Ä–∞–º–µ—Ç—Ä {param_type}",
                                line_number=self._get_line_number(content, match.start()),
                                description=f"–ó–Ω–∞—á–µ–Ω–∏–µ {param_type} ({value}) –º–æ–∂–µ—Ç –±—ã—Ç—å –Ω–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–º",
                                current_content=match.group(0),
                                suggested_improvement=f"–ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ç–∏–ø–∏—á–Ω—ã–º –¥–∏–∞–ø–∞–∑–æ–Ω–∞–º –¥–ª—è {param_type}",
                                reference_source="Technical validation patterns"
                            ))
                            score -= 5
                    
                    except ValueError:
                        issues.append(ValidationIssue(
                            issue_type=ContentIssueType.TECHNICAL_ACCURACY,
                            severity="minor",
                            section=f"–ü–∞—Ä–∞–º–µ—Ç—Ä {param_type}",
                            line_number=self._get_line_number(content, match.start()),
                            description=f"–ù–µ–∫–æ—Ä—Ä–µ–∫—Ç–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –∑–Ω–∞—á–µ–Ω–∏—è {param_type}",
                            current_content=match.group(0),
                            suggested_improvement="–ò—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å —á–∏—Å–ª–æ–≤–æ–π —Ñ–æ—Ä–º–∞—Ç —Å –µ–¥–∏–Ω–∏—Ü–∞–º–∏ –∏–∑–º–µ—Ä–µ–Ω–∏—è"
                        ))
                        score -= 2
        
        # Cross-reference validation with equipment specifications
        if equipment_type and reference_docs:
            equipment_issues, eq_score_deduction = self._cross_reference_equipment_specs(
                content, equipment_type, reference_docs)
            issues.extend(equipment_issues)
            score -= eq_score_deduction
        
        # Procedure logic validation
        procedure_issues, proc_score_deduction = self._validate_procedure_logic(content)
        issues.extend(procedure_issues)
        score -= proc_score_deduction
        
        return issues, max(score, 0)
    
    def _validate_completeness(self, content: str) -> Tuple[List[ValidationIssue], float, List[str]]:
        """Validate completeness against mandatory sections"""
        
        issues = []
        missing_sections = []
        score = 100.0
        
        # Use quality assessor for comprehensive completeness check
        assessment = self.quality_assessor.perform_comprehensive_assessment(content)
        
        # Convert assessment issues to validation issues
        for category_score in [assessment.technical_completeness, assessment.safety_coverage,
                             assessment.operational_clarity, assessment.regulatory_compliance,
                             assessment.professional_standards]:
            
            for issue in category_score.issues:
                severity_map = {"CRITICAL": "critical", "WARNING": "major", "SUGGESTION": "minor"}
                
                validation_issue = ValidationIssue(
                    issue_type=ContentIssueType.COMPLETENESS,
                    severity=severity_map.get(issue.level.value, "minor"),
                    section=issue.section,
                    line_number=None,
                    description=issue.description,
                    current_content="",
                    suggested_improvement=issue.improvement_suggestion
                )
                issues.append(validation_issue)
        
        # Extract missing sections
        found_sections, missing = self.quality_assessor.validate_section_presence(content)
        missing_sections = missing
        
        # Calculate completeness score
        total_sections = len(found_sections) + len(missing_sections)
        if total_sections > 0:
            score = (len(found_sections) / total_sections) * 100
        
        return issues, score, missing_sections
    
    def _validate_industry_standards(self, content: str, validation_level: ValidationLevel) -> Tuple[List[ValidationIssue], float]:
        """Validate against industry standards"""
        
        issues = []
        score = 100.0
        
        # Check for required standard references
        required_standards = []
        
        if validation_level in [ValidationLevel.PROFESSIONAL, ValidationLevel.PRODUCTION_READY]:
            required_standards.extend(["ISO 17025", "ICH Q2"])
        
        if validation_level == ValidationLevel.PRODUCTION_READY:
            required_standards.extend(["GMP", "21 CFR"])
        
        content_lower = content.lower()
        
        for standard in required_standards:
            standard_patterns = [
                standard.lower().replace(" ", r"\s*"),
                standard.replace(" ", ""),
                standard.replace(" ", "-")
            ]
            
            found = False
            for pattern in standard_patterns:
                if re.search(pattern, content_lower):
                    found = True
                    break
            
            if not found:
                issues.append(ValidationIssue(
                    issue_type=ContentIssueType.INDUSTRY_STANDARDS,
                    severity="major",
                    section="–ù–æ—Ä–º–∞—Ç–∏–≤–Ω—ã–µ —Å—Å—ã–ª–∫–∏",
                    line_number=None,
                    description=f"–û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç —Å—Å—ã–ª–∫–∞ –Ω–∞ —Å—Ç–∞–Ω–¥–∞—Ä—Ç {standard}",
                    current_content="",
                    suggested_improvement=f"–î–æ–±–∞–≤–∏—Ç—å —Å—Å—ã–ª–∫—É –Ω–∞ —Å—Ç–∞–Ω–¥–∞—Ä—Ç {standard} –≤ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π —Ä–∞–∑–¥–µ–ª",
                    regulatory_requirement=standard
                ))
                score -= 15
        
        # Check for specific standard requirements
        for standard_key, standard_info in self.industry_standards.items():
            if any(std_name in content_lower for std_name in [standard_key.lower(), standard_info["title"].lower()]):
                # Standard is referenced, check for required elements
                missing_elements = []
                
                for element in standard_info["required_elements"]:
                    element_keywords = element.lower().split()
                    if not any(keyword in content_lower for keyword in element_keywords):
                        missing_elements.append(element)
                
                if missing_elements:
                    issues.append(ValidationIssue(
                        issue_type=ContentIssueType.INDUSTRY_STANDARDS,
                        severity="major",
                        section=f"–°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ {standard_key}",
                        line_number=None,
                        description=f"–ù–µ –≤—ã–ø–æ–ª–Ω–µ–Ω—ã —Ç—Ä–µ–±–æ–≤–∞–Ω–∏—è —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞: {', '.join(missing_elements)}",
                        current_content="",
                        suggested_improvement=f"–î–æ–±–∞–≤–∏—Ç—å —Ä–∞–∑–¥–µ–ª—ã/–ø—Ä–æ—Ü–µ–¥—É—Ä—ã –¥–ª—è: {', '.join(missing_elements)}",
                        regulatory_requirement=standard_key
                    ))
                    score -= 10
        
        return issues, max(score, 0)
    
    def _validate_safety_compliance(self, content: str, equipment_type: str = None) -> Tuple[List[ValidationIssue], float]:
        """Validate safety compliance"""
        
        issues = []
        score = 100.0
        
        # Use safety integrator for comprehensive safety validation
        try:
            safety_analysis = self.safety_integrator.perform_comprehensive_safety_integration(
                content, equipment_type)
            
            # Convert safety gaps to validation issues
            for gap in safety_analysis.get("critical_safety_gaps", []):
                issues.append(ValidationIssue(
                    issue_type=ContentIssueType.SAFETY_COMPLIANCE,
                    severity="critical",
                    section="–ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å",
                    line_number=None,
                    description=gap,
                    current_content="",
                    suggested_improvement="–î–æ–±–∞–≤–∏—Ç—å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–µ –ø—Ä–æ—Ü–µ–¥—É—Ä—ã –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏"
                ))
                score -= 20
            
            # Check safety integration score
            safety_score = safety_analysis.get("safety_integration_score", 70)
            if safety_score < 80:
                issues.append(ValidationIssue(
                    issue_type=ContentIssueType.SAFETY_COMPLIANCE,
                    severity="major",
                    section="–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏",
                    line_number=None,
                    description="–ù–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–∞—è –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è –º–µ—Ä –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –≤ –ø—Ä–æ—Ü–µ–¥—É—Ä—ã",
                    current_content="",
                    suggested_improvement="–£—Å–∏–ª–∏—Ç—å –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—é —Ç—Ä–µ–±–æ–≤–∞–Ω–∏–π –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –≤–æ –≤—Å–µ —ç—Ç–∞–ø—ã –ø—Ä–æ—Ü–µ–¥—É—Ä—ã"
                ))
                score -= 15
        
        except Exception as e:
            # Fallback validation
            basic_safety_issues, basic_score_deduction = self._basic_safety_validation(content)
            issues.extend(basic_safety_issues)
            score -= basic_score_deduction
        
        return issues, max(score, 0)
    
    def _basic_safety_validation(self, content: str) -> Tuple[List[ValidationIssue], float]:
        """Basic safety validation as fallback"""
        
        issues = []
        score_deduction = 0
        
        safety_requirements = {
            "PPE requirements": [r'—Å–∏–∑|–∑–∞—â–∏—Ç–Ω.*—Å—Ä–µ–¥—Å—Ç–≤|–ø–µ—Ä—á–∞—Ç–∫|–æ—á–∫', "–¢—Ä–µ–±–æ–≤–∞–Ω–∏—è –∫ –°–ò–ó –Ω–µ —É–∫–∞–∑–∞–Ω—ã"],
            "Emergency procedures": [r'–∞–≤–∞—Ä–∏–π|—á—Ä–µ–∑–≤—ã—á–∞–π|—ç–∫—Å—Ç—Ä–µ–Ω', "–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç –∞–≤–∞—Ä–∏–π–Ω—ã–µ –ø—Ä–æ—Ü–µ–¥—É—Ä—ã"],
            "Hazard identification": [r'–æ–ø–∞—Å–Ω–æ—Å—Ç—å|—Ä–∏—Å–∫|–≤—Ä–µ–¥–Ω', "–ù–µ –ø—Ä–æ–≤–µ–¥–µ–Ω–∞ –∏–¥–µ–Ω—Ç–∏—Ñ–∏–∫–∞—Ü–∏—è –æ–ø–∞—Å–Ω–æ—Å—Ç–µ–π"],
            "Regulatory compliance": [r'–≥–æ—Å—Ç|—Å–∞–Ω–ø–∏–Ω|iso', "–û—Ç—Å—É—Ç—Å—Ç–≤—É—é—Ç —Å—Å—ã–ª–∫–∏ –Ω–∞ —Å—Ç–∞–Ω–¥–∞—Ä—Ç—ã –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏"]
        }
        
        content_lower = content.lower()
        
        for requirement, (pattern, description) in safety_requirements.items():
            if not re.search(pattern, content_lower):
                issues.append(ValidationIssue(
                    issue_type=ContentIssueType.SAFETY_COMPLIANCE,
                    severity="major",
                    section="–ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å",
                    line_number=None,
                    description=description,
                    current_content="",
                    suggested_improvement=f"–î–æ–±–∞–≤–∏—Ç—å —Ä–∞–∑–¥–µ–ª: {requirement}"
                ))
                score_deduction += 15
        
        return issues, score_deduction
    
    def _cross_reference_equipment_specs(self, 
                                       content: str, 
                                       equipment_type: str,
                                       reference_docs: List[str]) -> Tuple[List[ValidationIssue], float]:
        """Cross-reference content against equipment specifications"""
        
        issues = []
        score_deduction = 0
        
        # Identify equipment type and get specifications
        try:
            eq_type = self.equipment_engine.identify_equipment_type(equipment_type, reference_docs)
            
            # Extract context from reference documents
            context = {}
            for doc in reference_docs:
                doc_context = self.equipment_engine.extract_equipment_context(doc)
                # Merge contexts
                for key, value in doc_context.items():
                    if key not in context:
                        context[key] = value
                    elif isinstance(value, list):
                        context[key].extend(value)
            
            # Check if SOP parameters match equipment capabilities
            if context.get("parameters"):
                content_params = self._extract_parameters_from_content(content)
                
                for content_param, content_values in content_params.items():
                    if content_param in context["parameters"]:
                        ref_values = context["parameters"][content_param]
                        
                        # Simple validation - can be enhanced
                        if not self._parameters_match(content_values, ref_values):
                            issues.append(ValidationIssue(
                                issue_type=ContentIssueType.TECHNICAL_ACCURACY,
                                severity="major",
                                section="–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã",
                                line_number=None,
                                description=f"–ü–∞—Ä–∞–º–µ—Ç—Ä {content_param} –º–æ–∂–µ—Ç –Ω–µ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–æ–≤–∞—Ç—å —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞–º –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è",
                                current_content=str(content_values),
                                suggested_improvement="–ü—Ä–æ–≤–µ—Ä–∏—Ç—å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–º —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∞–º –æ–±–æ—Ä—É–¥–æ–≤–∞–Ω–∏—è",
                                reference_source="Equipment documentation"
                            ))
                            score_deduction += 5
        
        except Exception as e:
            # Log error but don't fail validation
            pass
        
        return issues, score_deduction
    
    def _validate_procedure_logic(self, content: str) -> Tuple[List[ValidationIssue], float]:
        """Validate logical flow and completeness of procedures"""
        
        issues = []
        score_deduction = 0
        
        # Check for step numbering consistency
        step_pattern = r'^\s*(\d+)\.\s+'
        step_matches = list(re.finditer(step_pattern, content, re.MULTILINE))
        
        if len(step_matches) > 1:
            expected_num = 1
            for match in step_matches:
                actual_num = int(match.group(1))
                if actual_num != expected_num:
                    issues.append(ValidationIssue(
                        issue_type=ContentIssueType.COMPLETENESS,
                        severity="minor",
                        section="–ù—É–º–µ—Ä–∞—Ü–∏—è —à–∞–≥–æ–≤",
                        line_number=self._get_line_number(content, match.start()),
                        description=f"–ù–∞—Ä—É—à–µ–Ω–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å –Ω—É–º–µ—Ä–∞—Ü–∏–∏: –æ–∂–∏–¥–∞–ª—Å—è —à–∞–≥ {expected_num}, –Ω–∞–π–¥–µ–Ω {actual_num}",
                        current_content=match.group(0),
                        suggested_improvement="–ò—Å–ø—Ä–∞–≤–∏—Ç—å –Ω—É–º–µ—Ä–∞—Ü–∏—é —à–∞–≥–æ–≤"
                    ))
                    score_deduction += 1
                expected_num += 1
        
        # Check for decision points and branching logic
        decision_patterns = [
            r'–µ—Å–ª–∏\s+.*,\s*—Ç–æ',
            r'–≤\s+—Å–ª—É—á–∞–µ\s+–µ—Å–ª–∏',
            r'–ø—Ä–∏\s+(?:–ø—Ä–µ–≤—ã—à–µ–Ω–∏–∏|–æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–∏|–Ω–µ—Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–∏)'
        ]
        
        decision_matches = 0
        for pattern in decision_patterns:
            decision_matches += len(re.findall(pattern, content, re.IGNORECASE))
        
        if decision_matches > 0:
            # Check if each decision point has clear outcomes
            unclear_decisions = re.findall(r'–µ—Å–ª–∏\s+[^,]{5,50},\s*—Ç–æ\s*[^\.]{0,20}[\.\n]', content, re.IGNORECASE)
            
            for unclear in unclear_decisions:
                issues.append(ValidationIssue(
                    issue_type=ContentIssueType.COMPLETENESS,
                    severity="major",
                    section="–õ–æ–≥–∏–∫–∞ –ø—Ä–æ—Ü–µ–¥—É—Ä",
                    line_number=None,
                    description="–ù–µ—è—Å–Ω–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω—ã –¥–µ–π—Å—Ç–≤–∏—è –ø—Ä–∏ –ø—Ä–∏–Ω—è—Ç–∏–∏ —Ä–µ—à–µ–Ω–∏—è",
                    current_content=unclear.strip(),
                    suggested_improvement="–ß–µ—Ç–∫–æ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –¥–µ–π—Å—Ç–≤–∏—è –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∏—Å—Ö–æ–¥–∞ —Ä–µ—à–µ–Ω–∏—è"
                ))
                score_deduction += 3
        
        return issues, score_deduction
    
    def _generate_enhancement_suggestions(self, 
                                        content: str, 
                                        issues: List[ValidationIssue],
                                        reference_docs: List[str] = None) -> List[Dict[str, Any]]:
        """Generate content enhancement suggestions"""
        
        suggestions = []
        
        # Analyze issue patterns to generate targeted suggestions
        issue_categories = {}
        for issue in issues:
            category = issue.issue_type.value
            if category not in issue_categories:
                issue_categories[category] = []
            issue_categories[category].append(issue)
        
        # Generate suggestions based on issue patterns
        for category, category_issues in issue_categories.items():
            if len(category_issues) >= 3:  # Multiple issues in same category
                if category == ContentIssueType.TECHNICAL_ACCURACY.value:
                    suggestions.append({
                        "type": "comprehensive_review",
                        "priority": "high",
                        "title": "–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å —Ç—Ä–µ–±—É–µ—Ç —É–ª—É—á—à–µ–Ω–∏—è",
                        "description": "–ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã —Å —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–º–∏ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞–º–∏",
                        "action": "–ü—Ä–æ–≤–µ—Å—Ç–∏ –∫–æ–º–ø–ª–µ–∫—Å–Ω—ã–π –ø–µ—Ä–µ—Å–º–æ—Ç—Ä –≤—Å–µ—Ö —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ —Å –ø—Ä–∏–≤–ª–µ—á–µ–Ω–∏–µ–º —ç–∫—Å–ø–µ—Ä—Ç–æ–≤",
                        "affected_sections": list(set([issue.section for issue in category_issues]))
                    })
                
                elif category == ContentIssueType.SAFETY_COMPLIANCE.value:
                    suggestions.append({
                        "type": "safety_integration",
                        "priority": "critical",
                        "title": "–¢—Ä–µ–±—É–µ—Ç—Å—è —É—Å–∏–ª–µ–Ω–∏–µ –º–µ—Ä –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏",
                        "description": "–í—ã—è–≤–ª–µ–Ω—ã –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–µ–ª—ã –≤ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏–∏ –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏",
                        "action": "–ü—Ä–æ–≤–µ—Å—Ç–∏ –∫–æ–º–ø–ª–µ–∫—Å–Ω—É—é –æ—Ü–µ–Ω–∫—É —Ä–∏—Å–∫–æ–≤ –∏ –∏–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å –º–µ—Ä—ã –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏ –≤–æ –≤—Å–µ –ø—Ä–æ—Ü–µ–¥—É—Ä—ã",
                        "affected_sections": list(set([issue.section for issue in category_issues]))
                    })
        
        # Generate content-specific enhancement suggestions
        content_suggestions = self._analyze_content_for_enhancements(content, reference_docs)
        suggestions.extend(content_suggestions)
        
        return suggestions
    
    def _analyze_content_for_enhancements(self, content: str, reference_docs: List[str] = None) -> List[Dict[str, Any]]:
        """Analyze content to identify enhancement opportunities"""
        
        suggestions = []
        
        # Check content length and depth
        if len(content) < 2000:
            suggestions.append({
                "type": "content_expansion",
                "priority": "medium",
                "title": "–î–æ–∫—É–º–µ–Ω—Ç —Ç—Ä–µ–±—É–µ—Ç —Ä–∞—Å—à–∏—Ä–µ–Ω–∏—è",
                "description": "–°–æ–¥–µ—Ä–∂–∞–Ω–∏–µ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ –¥–µ—Ç–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω–æ –¥–ª—è –ø—Ä–æ–∏–∑–≤–æ–¥—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è",
                "action": "–î–æ–±–∞–≤–∏—Ç—å –¥–µ—Ç–∞–ª—å–Ω—ã–µ –ø—Ä–æ—Ü–µ–¥—É—Ä—ã, —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–∏ –∏ –ø—Ä–∏–º–µ—Ä—ã",
                "affected_sections": ["–í—Å–µ —Ä–∞–∑–¥–µ–ª—ã"]
            })
        
        # Check for generic vs specific content
        generic_phrases = [
            "–ø—Ä–æ–≤–µ—Ä–∏—Ç—å –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç—å", "—É–±–µ–¥–∏—Ç—å—Å—è –≤ —Ä–∞–±–æ—Ç–æ—Å–ø–æ—Å–æ–±–Ω–æ—Å—Ç–∏", 
            "–≤—ã–ø–æ–ª–Ω–∏—Ç—å –Ω–µ–æ–±—Ö–æ–¥–∏–º—ã–µ –¥–µ–π—Å—Ç–≤–∏—è", "–ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏"
        ]
        
        generic_count = sum(1 for phrase in generic_phrases if phrase in content.lower())
        
        if generic_count > 3:
            suggestions.append({
                "type": "specificity_improvement", 
                "priority": "high",
                "title": "–ó–∞–º–µ–Ω–∞ –æ–±—â–∏—Ö —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–æ–∫ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º–∏ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º–∏",
                "description": f"–ù–∞–π–¥–µ–Ω–æ {generic_count} –æ–±—â–∏—Ö —Ñ–æ—Ä–º—É–ª–∏—Ä–æ–≤–æ–∫, —Ç—Ä–µ–±—É—é—â–∏—Ö –∫–æ–Ω–∫—Ä–µ—Ç–∏–∑–∞—Ü–∏–∏",
                "action": "–ó–∞–º–µ–Ω–∏—Ç—å –æ–±—â–∏–µ —Ñ—Ä–∞–∑—ã –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–º–∏, –∏–∑–º–µ—Ä–∏–º—ã–º–∏ –∏–Ω—Å—Ç—Ä—É–∫—Ü–∏—è–º–∏",
                "affected_sections": ["–ü—Ä–æ—Ü–µ–¥—É—Ä—ã"]
            })
        
        # Check for missing tables and structured data
        table_count = content.count("|")  # Simple markdown table detection
        param_count = len(re.findall(r'\d+(?:\.\d+)?\s*[¬∞‚ÑÉ–±–∞—Ä–º–ª–º–∏–Ω]', content))
        
        if param_count > 5 and table_count < 10:
            suggestions.append({
                "type": "structure_improvement",
                "priority": "medium", 
                "title": "–°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–∏–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –¥–∞–Ω–Ω—ã—Ö",
                "description": "–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –ª—É—á—à–µ –ø—Ä–µ–¥—Å—Ç–∞–≤–∏—Ç—å –≤ —Ç–∞–±–ª–∏—á–Ω–æ–º –≤–∏–¥–µ",
                "action": "–°–æ–∑–¥–∞—Ç—å —Ç–∞–±–ª–∏—Ü—ã –¥–ª—è —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤, —Å–ø–µ—Ü–∏—Ñ–∏–∫–∞—Ü–∏–π –∏ –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤",
                "affected_sections": ["–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏", "–ü–∞—Ä–∞–º–µ—Ç—Ä—ã"]
            })
        
        # Reference document integration suggestions
        if reference_docs and len(reference_docs) > 0:
            suggestions.append({
                "type": "reference_integration",
                "priority": "high",
                "title": "–ò–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è —Å–ø—Ä–∞–≤–æ—á–Ω—ã—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤",
                "description": "–î–æ—Å—Ç—É–ø–Ω—ã —Å–ø—Ä–∞–≤–æ—á–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã –¥–ª—è —É–ª—É—á—à–µ–Ω–∏—è —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è",
                "action": "–ò–Ω—Ç–µ–≥—Ä–∏—Ä–æ–≤–∞—Ç—å –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∏–∑ —Å–ø—Ä–∞–≤–æ—á–Ω—ã—Ö –º–∞—Ç–µ—Ä–∏–∞–ª–æ–≤",
                "affected_sections": ["–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∏–µ —Ö–∞—Ä–∞–∫—Ç–µ—Ä–∏—Å—Ç–∏–∫–∏", "–ü—Ä–æ—Ü–µ–¥—É—Ä—ã"]
            })
        
        return suggestions
    
    def generate_validation_report(self, validation_result: ContentValidationResult) -> str:
        """Generate comprehensive validation report"""
        
        report = []
        report.append("# –û–¢–ß–ï–¢ –û –í–ê–õ–ò–î–ê–¶–ò–ò –°–û–î–ï–†–ñ–ê–ù–ò–Ø –°–û–ü\n")
        
        # Overall assessment
        report.append("## –û–±—â–∞—è –æ—Ü–µ–Ω–∫–∞\n")
        report.append(f"**–û–±—â–∏–π –±–∞–ª–ª:** {validation_result.overall_score:.1f}/100")
        report.append(f"**–î–æ—Å—Ç–∏–≥–Ω—É—Ç—ã–π —É—Ä–æ–≤–µ–Ω—å –≤–∞–ª–∏–¥–∞—Ü–∏–∏:** {validation_result.validation_level.value}")
        report.append("")
        
        # Category scores
        report.append("## –û—Ü–µ–Ω–∫–∞ –ø–æ –∫–∞—Ç–µ–≥–æ—Ä–∏—è–º\n")
        report.append(f"- **–¢–µ—Ö–Ω–∏—á–µ—Å–∫–∞—è —Ç–æ—á–Ω–æ—Å—Ç—å:** {validation_result.technical_accuracy_score:.1f}/100")
        report.append(f"- **–ü–æ–ª–Ω–æ—Ç–∞ —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è:** {validation_result.completeness_score:.1f}/100") 
        report.append(f"- **–°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º:** {validation_result.regulatory_score:.1f}/100")
        report.append(f"- **–ë–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç—å:** {validation_result.safety_score:.1f}/100")
        report.append("")
        
        # Issues summary
        if validation_result.issues:
            report.append("## –í—ã—è–≤–ª–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã\n")
            
            # Group issues by severity
            critical_issues = [i for i in validation_result.issues if i.severity == "critical"]
            major_issues = [i for i in validation_result.issues if i.severity == "major"]
            minor_issues = [i for i in validation_result.issues if i.severity == "minor"]
            
            if critical_issues:
                report.append("### ‚ùå –ö—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–±–ª–µ–º—ã\n")
                for issue in critical_issues:
                    report.append(f"**{issue.section}:** {issue.description}")
                    report.append(f"*–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:* {issue.suggested_improvement}")
                    report.append("")
            
            if major_issues:
                report.append("### ‚ö†Ô∏è –ó–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã\n")
                for issue in major_issues[:10]:  # Limit to first 10
                    report.append(f"**{issue.section}:** {issue.description}")
                    report.append(f"*–†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏—è:* {issue.suggested_improvement}")
                    report.append("")
            
            if minor_issues:
                report.append(f"### ‚ÑπÔ∏è –ù–µ–∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã–µ –∑–∞–º–µ—á–∞–Ω–∏—è ({len(minor_issues)} —à—Ç.)\n")
                for issue in minor_issues[:5]:  # Show first 5
                    report.append(f"- {issue.description}")
                if len(minor_issues) > 5:
                    report.append(f"... –∏ –µ—â–µ {len(minor_issues) - 5} –∑–∞–º–µ—á–∞–Ω–∏–π")
                report.append("")
        
        # Enhancement suggestions
        if validation_result.enhancement_suggestions:
            report.append("## –ü—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø–æ —É–ª—É—á—à–µ–Ω–∏—é\n")
            
            for suggestion in validation_result.enhancement_suggestions:
                priority_emoji = {"critical": "üî•", "high": "‚ö°", "medium": "üìã", "low": "üí°"}
                emoji = priority_emoji.get(suggestion["priority"], "üìã")
                
                report.append(f"### {emoji} {suggestion['title']}")
                report.append(f"**–ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç:** {suggestion['priority']}")
                report.append(f"**–û–ø–∏—Å–∞–Ω–∏–µ:** {suggestion['description']}")
                report.append(f"**–†–µ–∫–æ–º–µ–Ω–¥—É–µ–º—ã–µ –¥–µ–π—Å—Ç–≤–∏—è:** {suggestion['action']}")
                
                if suggestion.get("affected_sections"):
                    report.append(f"**–ó–∞—Ç—Ä–æ–Ω—É—Ç—ã–µ —Ä–∞–∑–¥–µ–ª—ã:** {', '.join(suggestion['affected_sections'])}")
                report.append("")
        
        # Missing sections
        if validation_result.missing_sections:
            report.append("## –û—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ —Ä–∞–∑–¥–µ–ª—ã\n")
            for section in validation_result.missing_sections:
                report.append(f"- {section}")
            report.append("")
        
        # Recommendations for next steps
        report.append("## –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏ –ø–æ –¥–∞–ª—å–Ω–µ–π—à–∏–º –¥–µ–π—Å—Ç–≤–∏—è–º\n")
        
        if validation_result.overall_score < 70:
            report.append("üö® **–¢—Ä–µ–±—É–µ—Ç—Å—è –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω–∞—è –ø–µ—Ä–µ—Ä–∞–±–æ—Ç–∫–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞**")
            report.append("- –£—Å—Ç—Ä–∞–Ω–∏—Ç–µ –≤—Å–µ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–±–ª–µ–º—ã")
            report.append("- –î–æ–±–∞–≤—å—Ç–µ –æ—Ç—Å—É—Ç—Å—Ç–≤—É—é—â–∏–µ –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ —Ä–∞–∑–¥–µ–ª—ã")
            report.append("- –ü—Ä–æ–≤–µ–¥–∏—Ç–µ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫—É—é —ç–∫—Å–ø–µ—Ä—Ç–∏–∑—É —Å–æ–¥–µ—Ä–∂–∞–Ω–∏—è")
        elif validation_result.overall_score < 85:
            report.append("‚ö†Ô∏è **–¢—Ä–µ–±—É–µ—Ç—Å—è –¥–æ—Ä–∞–±–æ—Ç–∫–∞ –ø–µ—Ä–µ–¥ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ–º**")
            report.append("- –£—Å—Ç—Ä–∞–Ω–∏—Ç–µ –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–±–ª–µ–º—ã")
            report.append("- –†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø–æ —É–ª—É—á—à–µ–Ω–∏—é")
            report.append("- –ü—Ä–æ–≤–µ–¥–∏—Ç–µ –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω—É—é –ø—Ä–æ–≤–µ—Ä–∫—É —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö –ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤")
        else:
            report.append("‚úÖ **–î–æ–∫—É–º–µ–Ω—Ç –±–ª–∏–∑–æ–∫ –∫ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç–∏ –∫ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—é**")
            report.append("- –£—Å—Ç—Ä–∞–Ω–∏—Ç–µ –æ—Å—Ç–∞–≤—à–∏–µ—Å—è –∫—Ä–∏—Ç–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–±–ª–µ–º—ã")
            report.append("- –†–∞—Å—Å–º–æ—Ç—Ä–∏—Ç–µ –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –ø–æ —É–ª—É—á—à–µ–Ω–∏—é –∫–∞—á–µ—Å—Ç–≤–∞")
            report.append("- –ü—Ä–æ–≤–µ–¥–∏—Ç–µ —Ñ–∏–Ω–∞–ª—å–Ω—É—é –ø—Ä–æ–≤–µ—Ä–∫—É –ø–µ—Ä–µ–¥ —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ–º")
        
        report.append("")
        
        return "\n".join(report)
    
    # Helper methods
    def _get_line_number(self, content: str, position: int) -> int:
        """Get line number for a given position in content"""
        return content[:position].count('\n') + 1
    
    def _extract_parameters_from_content(self, content: str) -> Dict[str, List[Dict[str, Any]]]:
        """Extract technical parameters from content"""
        parameters = {}
        
        # Temperature parameters
        temp_matches = re.findall(r'—Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä[–∞–µ—ã]?\s*[:\-]?\s*(\d+(?:\.\d+)?)\s*[¬∞‚ÑÉ]?([CF]?)', content, re.IGNORECASE)
        if temp_matches:
            parameters["—Ç–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞"] = [{"value": match[0], "unit": "¬∞C"} for match in temp_matches]
        
        # Pressure parameters  
        pressure_matches = re.findall(r'–¥–∞–≤–ª–µ–Ω–∏[–µ—è]?\s*[:\-]?\s*(\d+(?:\.\d+)?)\s*(–±–∞—Ä|bar|–∫–ü–∞|–ú–ü–∞|–∞—Ç–º)', content, re.IGNORECASE)
        if pressure_matches:
            parameters["–¥–∞–≤–ª–µ–Ω–∏–µ"] = [{"value": match[0], "unit": match[1]} for match in pressure_matches]
        
        return parameters
    
    def _parameters_match(self, content_values: List[Dict], ref_values: List[Dict]) -> bool:
        """Check if content parameters match reference values"""
        # Simplified matching logic - can be enhanced
        if not content_values or not ref_values:
            return True
        
        # Check if at least one content value matches reference range
        for content_val in content_values:
            try:
                val = float(content_val["value"])
                for ref_val in ref_values:
                    try:
                        ref_num = float(ref_val["value"])
                        # Allow 20% tolerance
                        if 0.8 * ref_num <= val <= 1.2 * ref_num:
                            return True
                    except ValueError:
                        continue
            except ValueError:
                continue
        
        return False
    
    def _determine_validation_level(self, overall_score: float, issues: List[ValidationIssue]) -> ValidationLevel:
        """Determine achieved validation level"""
        
        critical_issues = [i for i in issues if i.severity == "critical"]
        
        if overall_score >= 95 and len(critical_issues) == 0:
            return ValidationLevel.PRODUCTION_READY
        elif overall_score >= 80 and len(critical_issues) <= 1:
            return ValidationLevel.PROFESSIONAL
        else:
            return ValidationLevel.BASIC